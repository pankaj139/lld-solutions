# Distributed Cache System - Low Level Design

## ðŸ”— Implementation Links

- **Python Implementation**: [python/distributed-cache/main.py](python/distributed-cache/main.py)
- **JavaScript Implementation**: [javascript/distributed-cache/main.js](javascript/distributed-cache/main.js)

## Problem Statement

Design and implement a distributed cache system that supports high-performance key-value storage across multiple nodes. The system should handle consistent hashing for data distribution, cache eviction policies, replication for fault tolerance, and provide APIs for cache operations with strong consistency guarantees.

## Functional Requirements

### Core Cache Operations

1. **Basic Operations**
   - Put(key, value, ttl) - Store key-value pair with optional TTL
   - Get(key) - Retrieve value by key
   - Delete(key) - Remove key-value pair
   - Exists(key) - Check if key exists
   - Clear() - Remove all cached data

2. **Advanced Operations**
   - GetMultiple(keys) - Batch retrieve multiple keys
   - PutMultiple(data) - Batch store multiple key-value pairs
   - Increment(key, delta) - Atomic increment operation
   - Decrement(key, delta) - Atomic decrement operation
   - GetAndSet(key, value) - Atomic get and set operation

3. **Expiration Management**
   - Time-To-Live (TTL) support
   - Automatic cleanup of expired entries
   - Touch(key, ttl) - Update TTL for existing key
   - GetTTL(key) - Get remaining time to live

### Distributed System Features

1. **Node Management**
   - Add nodes to the cluster
   - Remove nodes from the cluster
   - Node health monitoring
   - Automatic failover handling

2. **Data Distribution**
   - Consistent hashing for key distribution
   - Virtual nodes for better load balancing
   - Automatic data migration during scaling
   - Hash ring visualization

3. **Replication**
   - Configurable replication factor
   - Read/write quorum support
   - Anti-entropy mechanisms
   - Conflict resolution strategies

4. **Consistency Models**
   - Strong consistency (synchronous replication)
   - Eventual consistency (asynchronous replication)
   - Read-your-writes consistency
   - Monotonic read consistency

## Non-Functional Requirements

1. **Performance**
   - Sub-millisecond response times for local operations
   - High throughput (100K+ operations per second)
   - Efficient memory utilization
   - Minimal network overhead

2. **Scalability**
   - Horizontal scaling with consistent hashing
   - Support for thousands of nodes
   - Linear performance scaling
   - Automatic load balancing

3. **Availability**
   - 99.9%+ uptime with proper replication
   - Graceful degradation during failures
   - Fast recovery from node failures
   - No single point of failure

4. **Reliability**
   - Data durability with replication
   - Consistent data across replicas
   - Corruption detection and recovery
   - Comprehensive monitoring and alerting

## Core Classes and Design Patterns

### 1. Strategy Pattern (Cache Eviction Policies)

```python
class EvictionPolicy:
    """Base class for cache eviction strategies"""

class LRUEvictionPolicy(EvictionPolicy):
    """Least Recently Used eviction policy"""

class LFUEvictionPolicy(EvictionPolicy):
    """Least Frequently Used eviction policy"""

class TTLEvictionPolicy(EvictionPolicy):
    """Time To Live based eviction policy"""

class FIFOEvictionPolicy(EvictionPolicy):
    """First In First Out eviction policy"""
```

### 2. Observer Pattern (Node Monitoring)

```python
class NodeObserver:
    """Base class for node state observers"""

class HealthMonitor(NodeObserver):
    """Monitors node health and triggers alerts"""

class LoadBalancer(NodeObserver):
    """Observes node load and redistributes requests"""

class ReplicationManager(NodeObserver):
    """Manages data replication based on node state"""
```

### 3. Command Pattern (Distributed Operations)

```python
class CacheCommand:
    """Base class for cache operations"""

class PutCommand(CacheCommand):
class GetCommand(CacheCommand):
class DeleteCommand(CacheCommand):
class ReplicateCommand(CacheCommand):
```

### 4. Proxy Pattern (Remote Cache Access)

```python
class CacheProxy:
    """Proxy for remote cache node access"""

class LocalCacheProxy(CacheProxy):
    """Direct access to local cache"""

class RemoteCacheProxy(CacheProxy):
    """Network access to remote cache nodes"""
```

## Architecture Components

### Core Components

1. **DistributedCache**
   - Main facade for cache operations
   - Coordinates operations across nodes
   - Handles request routing
   - Manages consistency protocols

2. **CacheNode**
   - Individual cache instance
   - Local key-value storage
   - Health monitoring
   - Inter-node communication

3. **ConsistentHashRing**
   - Hash ring implementation
   - Virtual node management
   - Key-to-node mapping
   - Ring rebalancing

4. **ReplicationManager**
   - Replica placement strategy
   - Synchronization protocols
   - Conflict resolution
   - Anti-entropy processes

5. **EvictionManager**
   - Policy-based eviction
   - Memory management
   - TTL expiration handling
   - Statistics tracking

### Supporting Components

1. **NetworkLayer**
   - Inter-node communication
   - Protocol implementation
   - Connection pooling
   - Failure detection

2. **ConfigurationManager**
   - Cluster configuration
   - Dynamic reconfiguration
   - Settings validation
   - Version management

3. **MonitoringSystem**
   - Performance metrics
   - Health monitoring
   - Alerting system
   - Log aggregation

4. **SerializationManager**
   - Data serialization/deserialization
   - Compression support
   - Format versioning
   - Type safety

## Detailed Implementation

### Class Relationships

```text
DistributedCache
â”œâ”€â”€ ConsistentHashRing
â”œâ”€â”€ CacheNode[]
â”‚   â”œâ”€â”€ LocalCache
â”‚   â”œâ”€â”€ EvictionManager
â”‚   â””â”€â”€ NetworkLayer
â”œâ”€â”€ ReplicationManager
â”œâ”€â”€ ConfigurationManager
â””â”€â”€ MonitoringSystem
```

### Key Algorithms

1. **Consistent Hashing Algorithm**

   ```text
   1. Create hash ring with virtual nodes
   2. Map each physical node to multiple virtual nodes
   3. For each key, find successor node on ring
   4. Handle node addition/removal with minimal redistribution
   ```

2. **Replication Strategy**

   ```text
   1. Identify N successor nodes for each key
   2. Write to all replica nodes (sync/async)
   3. Handle read quorum requirements
   4. Resolve conflicts using vector clocks
   ```

3. **Cache Eviction Algorithm**

   ```text
   1. Monitor cache usage and apply eviction policy
   2. LRU: Remove least recently used items
   3. LFU: Remove least frequently used items
   4. TTL: Remove expired items automatically
   ```

## API Design

### Primary Interface

```python
class DistributedCache:
    def __init__(self, config: CacheConfig)
    def put(self, key: str, value: Any, ttl: int = None) -> bool
    def get(self, key: str) -> Optional[Any]
    def delete(self, key: str) -> bool
    def exists(self, key: str) -> bool
    def clear(self) -> bool
    
    def get_multiple(self, keys: List[str]) -> Dict[str, Any]
    def put_multiple(self, data: Dict[str, Any], ttl: int = None) -> bool
    def increment(self, key: str, delta: int = 1) -> int
    def decrement(self, key: str, delta: int = 1) -> int
    def get_and_set(self, key: str, value: Any) -> Optional[Any]
    
    def add_node(self, node: CacheNode) -> bool
    def remove_node(self, node_id: str) -> bool
    def get_cluster_info(self) -> ClusterInfo
    def get_statistics(self) -> CacheStatistics
```

### Configuration Interface

```python
class CacheConfig:
    def __init__(self):
        self.max_memory: int = 1024 * 1024 * 1024  # 1GB
        self.eviction_policy: str = "LRU"
        self.replication_factor: int = 3
        self.consistency_level: str = "QUORUM"
        self.virtual_nodes: int = 150
        self.default_ttl: int = 3600  # 1 hour
        self.health_check_interval: int = 30  # seconds
```

## Error Handling

### Exception Hierarchy

```python
class CacheException(Exception): pass
class KeyNotFoundException(CacheException): pass
class NodeUnavailableException(CacheException): pass
class ReplicationException(CacheException): pass
class ConsistencyException(CacheException): pass
class ConfigurationException(CacheException): pass
class NetworkException(CacheException): pass
class SerializationException(CacheException): pass
```

### Error Scenarios

1. **Network Errors**
   - Node communication failures
   - Network partitions
   - Timeout handling

2. **Consistency Errors**
   - Write conflicts
   - Read repair failures
   - Quorum not met

3. **Resource Errors**
   - Memory exhaustion
   - Storage limits exceeded
   - Connection pool exhaustion

## Distributed Systems Concepts

### Consistent Hashing

1. **Hash Ring Implementation**
   - SHA-1 hashing for key distribution
   - Virtual nodes for better load distribution
   - Clockwise successor selection
   - Minimal data movement during scaling

2. **Virtual Nodes Benefits**
   - Better load balancing
   - Faster rebalancing
   - Reduced hotspots
   - Improved fault tolerance

### Replication Strategies

1. **Synchronous Replication**
   - Strong consistency guarantees
   - Higher latency for writes
   - Immediate consistency
   - CAP theorem: CP system

2. **Asynchronous Replication**
   - Higher write performance
   - Eventual consistency
   - Risk of data loss
   - CAP theorem: AP system

### Consistency Models

1. **Strong Consistency**
   - All reads return the most recent write
   - Synchronous replication required
   - Higher latency, lower availability

2. **Eventual Consistency**
   - System will become consistent over time
   - Higher availability and performance
   - Temporary inconsistencies possible

## Performance Optimization

### Memory Management

1. **Efficient Data Structures**
   - Hash tables for O(1) lookup
   - Doubly linked lists for LRU
   - Skip lists for sorted access
   - Memory pools for allocation

2. **Compression**
   - Value compression for large objects
   - Delta compression for updates
   - Dictionary compression for keys
   - Adaptive compression based on patterns

### Network Optimization

1. **Connection Pooling**
   - Persistent connections between nodes
   - Connection reuse and management
   - Load balancing across connections
   - Connection health monitoring

2. **Batching**
   - Batch multiple operations
   - Reduce network round trips
   - Pipeline processing
   - Asynchronous operation queuing

## Testing Strategy

### Unit Tests

1. **Core Operations**
   - Basic CRUD operations
   - Eviction policy correctness
   - TTL expiration handling
   - Consistency guarantees

2. **Distributed Logic**
   - Consistent hashing accuracy
   - Replication correctness
   - Node failure handling
   - Data migration

### Integration Tests

1. **Multi-Node Scenarios**
   - Cluster formation
   - Node addition/removal
   - Network partition handling
   - Data consistency verification

2. **Performance Tests**
   - Throughput benchmarks
   - Latency measurements
   - Memory usage analysis
   - Scalability testing

### Chaos Testing

1. **Failure Scenarios**
   - Random node failures
   - Network partitions
   - Disk failures
   - Memory pressure

2. **Recovery Testing**
   - Automatic failover
   - Data recovery
   - Cluster reformation
   - Performance degradation

## Extension Points

### Custom Eviction Policies

1. **Plugin Architecture**
   - Custom eviction algorithms
   - Policy combination strategies
   - Adaptive policies
   - Machine learning integration

2. **Specialized Policies**
   - Size-based eviction
   - Cost-based eviction
   - Priority-based eviction
   - Application-specific policies

### Advanced Features

1. **Bloom Filters**
   - Negative lookup optimization
   - Memory-efficient existence checks
   - False positive handling
   - Dynamic filter sizing

2. **Compression Algorithms**
   - Pluggable compression
   - Adaptive compression
   - Format detection
   - Performance tuning

## Interview Discussion Points

### Design Decisions

1. **Why Consistent Hashing?**
   - Minimal data movement during scaling
   - Uniform load distribution
   - Decentralized architecture
   - Fault tolerance benefits

2. **Replication vs. Sharding Trade-offs**
   - Availability vs. consistency
   - Storage overhead vs. fault tolerance
   - Read performance vs. write complexity
   - Recovery time considerations

3. **Eviction Policy Selection**
   - Workload pattern analysis
   - Memory vs. computation trade-offs
   - Hit ratio optimization
   - Real-time vs. batch processing

### Scalability Questions

1. **How to handle hotspots?**
   - Virtual node redistribution
   - Dynamic load balancing
   - Caching layer architecture
   - Traffic shaping techniques

2. **Network partition handling?**
   - Split-brain prevention
   - Quorum-based decisions
   - Eventual consistency mechanisms
   - Manual intervention procedures

3. **Memory management at scale?**
   - Hierarchical caching
   - Compression strategies
   - Memory pooling
   - Garbage collection optimization

### Alternative Designs

1. **Centralized vs. Decentralized**
   - Master-slave architecture
   - Peer-to-peer systems
   - Hybrid approaches
   - Consensus protocols

2. **Storage Layer Options**
   - In-memory only
   - Persistent storage
   - Hybrid storage tiers
   - External storage integration

3. **Consistency Protocols**
   - Raft consensus
   - PBFT algorithms
   - Vector clocks
   - Logical timestamps

## Real-World Applications

1. **Web Application Caching**
   - Session storage
   - Database query caching
   - API response caching
   - Static content caching

2. **Microservices Architecture**
   - Service discovery
   - Configuration management
   - Inter-service communication
   - Load balancing

3. **Big Data Processing**
   - Intermediate result caching
   - Computation memoization
   - Data pipeline optimization
   - Real-time analytics

4. **Content Delivery Networks**
   - Edge caching
   - Origin server offloading
   - Geographic distribution
   - Dynamic content caching

5. **Gaming Systems**
   - Player state caching
   - Leaderboard management
   - Real-time game data
   - Cross-region synchronization

## Advanced Topics

### Vector Clocks

1. **Conflict Detection**
   - Concurrent write identification
   - Causality relationship tracking
   - Version vector maintenance
   - Conflict resolution strategies

2. **Implementation Details**
   - Clock advancement rules
   - Memory optimization
   - Clock pruning strategies
   - Performance considerations

### Anti-Entropy Mechanisms

1. **Merkle Trees**
   - Efficient difference detection
   - Hierarchical comparison
   - Incremental synchronization
   - Bandwidth optimization

2. **Gossip Protocols**
   - Epidemic information spread
   - Eventual consistency guarantees
   - Failure detection
   - Membership management

This distributed cache system design demonstrates advanced distributed systems concepts including consistent hashing, replication strategies, consistency models, and fault tolerance mechanisms - making it an excellent problem for senior software engineer and system design interviews, especially for companies dealing with large-scale distributed systems.